{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hkZvKSF6r63",
    "outputId": "73c3c777-86b6-4c64-eaef-df020f3cefcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in e:\\anaconda_setup\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imutils in e:\\anaconda_setup\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Requirement already satisfied: opencv-python in e:\\anaconda_setup\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in e:\\anaconda_setup\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "%pip install SimpleITK\n",
    "%pip install imutils\n",
    "%pip install opencv-python\n",
    "import SimpleITK as sitk\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hoVyXmOH6r65"
   },
   "outputs": [],
   "source": [
    "# function to resample the image\n",
    "def resampling(image, spacing = (0.5, 0.5, 3), is_label = False):\n",
    "    Dimension = image.GetDimension()\n",
    " # get original spacing and size\n",
    "    original_spacing = image.GetSpacing()\n",
    "    original_size = image.GetSize()\n",
    "\n",
    "    # convert our z, y, x convention to SimpleITK's convention\n",
    "    out_spacing = list(spacing)[::-1]\n",
    "        # calculate output size in voxels\n",
    "    out_size = [\n",
    "        int(np.round(\n",
    "            size * (spacing_in / spacing_out)\n",
    "        ))\n",
    "        for size, spacing_in, spacing_out in zip(original_size, original_spacing, out_spacing)\n",
    "    ]\n",
    "\n",
    "    Resampler_func = sitk.ResampleImageFilter()\n",
    "    Resampler_func.SetReferenceImage(image)\n",
    "    Resampler_func.SetTransform(sitk.AffineTransform(Dimension))\n",
    "    Resampler_func.SetOutputSpacing(out_spacing) \n",
    "    Resampler_func.SetSize(out_size)\n",
    "    Resampler_func.SetOutputDirection(image.GetDirection())\n",
    "    Resampler_func.SetOutputOrigin(image.GetOrigin())\n",
    "    Resampler_func.SetDefaultPixelValue(image.GetPixelIDValue())\n",
    "    if is_label:\n",
    "        Resampler_func.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    else:\n",
    "        Resampler_func.SetInterpolator(sitk.sitkBSpline)\n",
    "\n",
    "    ResImage = Resampler_func.Execute(image)\n",
    "    return ResImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Tt1gx4Is6r66"
   },
   "outputs": [],
   "source": [
    "def crop_or_pad(image):\n",
    "    size = (300, 300, 16)\n",
    "    # set identity operations for cropping and padding\n",
    "    rank = len(size)\n",
    "    padding = [[0, 0] for _ in range(rank)]\n",
    "    slicer = [slice(None) for _ in range(rank)]\n",
    "    shape = image.GetSize()\n",
    "    # for each dimension, determine process (cropping or padding)\n",
    "    for i in range(rank):\n",
    "        if shape[i] < size[i]:\n",
    "            # set padding settings\n",
    "            padding[i][0] = (size[i] - shape[i]) // 2\n",
    "            padding[i][1] = size[i] - shape[i] - padding[i][0]\n",
    "        else:\n",
    "            # create slicer object to crop image\n",
    "            idx_start = int(np.floor((shape[i] - size[i]) / 2.))\n",
    "            idx_end = idx_start + size[i]\n",
    "            slicer[i] = slice(idx_start, idx_end)\n",
    "\n",
    "    # crop and/or pad image\n",
    "    if isinstance(image, sitk.Image):\n",
    "        pad_filter = sitk.ConstantPadImageFilter()\n",
    "        pad_filter.SetPadLowerBound([pad[0] for pad in padding])\n",
    "        pad_filter.SetPadUpperBound([pad[1] for pad in padding])\n",
    "        return pad_filter.Execute(image[tuple(slicer)])\n",
    "    else:\n",
    "        return np.pad(image[tuple(slicer)], padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BDhKk6J-6r66"
   },
   "outputs": [],
   "source": [
    "def slicing(image):\n",
    "    size_z = image.GetSize()[2]\n",
    "    sliced_images = []\n",
    "    # Extract the slice from the MRI volume\n",
    "    num_slices = 16\n",
    "\n",
    "    # Compute the slice thickness\n",
    "    slice_thickness = int(size_z / num_slices)\n",
    "\n",
    "    # Loop through each slice in the z-axis and save it as a separate image\n",
    "    for i in range(num_slices):\n",
    "    # Compute the slice index\n",
    "        slice_index = i * slice_thickness\n",
    "\n",
    "        # Extract the slice from the input image\n",
    "        slice_image = image[:, :, slice_index:slice_index+slice_thickness]\n",
    "\n",
    "        # Resample the slice to 300x300 pixels\n",
    "        image_slice_resampled = sitk.Resample(slice_image, [300, 300], sitk.Transform(), sitk.sitkLinear, slice_image.GetOrigin(), [slice_image.GetSpacing()[0], slice_image.GetSpacing()[1]], slice_image.GetDirection(), 0.0, slice_image.GetPixelID())\n",
    "        sliced_images.append(image_slice_resampled)\n",
    "    return sliced_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "de4k3SuO6r66"
   },
   "outputs": [],
   "source": [
    "def flipping_image(image):\n",
    "    # use sitk Flip function, where the True, False, false specifies to flip horizontally\n",
    "    flipped_image = sitk.Flip(image, [True, False, False])\n",
    "    return flipped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oigmPnvi6r67"
   },
   "outputs": [],
   "source": [
    "def normalized(image):\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the pixel values\n",
    "    mean = np.mean(image_array)\n",
    "    std = np.std(image_array)\n",
    "    \n",
    "    # Normalize the pixel values using z-score\n",
    "    normalized_array = (image_array - mean) / std\n",
    "    \n",
    "    # Create a new SimpleITK image from the normalized pixel array\n",
    "    normalized_image = sitk.GetImageFromArray(normalized_array)\n",
    "    normalized_image.CopyInformation(image)\n",
    "    \n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6936\\3159147097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0msliced_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflipImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msliced_test_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                     \u001b[0msliced_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mmask_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcroppedImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# path to all the volumes and masks\n",
    "dataPaths = [r\"E:\\projects\\image_processing\\picai_public_images_fold0\", \n",
    "            r\"E:\\projects\\image_processing\\picai_public_images_fold1\",\n",
    "             r\"E:\\projects\\image_processing\\picai_public_images_fold2\",\n",
    "            r\"E:\\projects\\image_processing\\picai_public_images_fold3\",\n",
    "            r\"E:\\projects\\image_processing\\picai_public_images_fold4\",\n",
    "            r\"E:\\projects\\image_processing\\picai_labels\\anatomical_delineations\\whole_gland\\AI\\Bosma22b\",\n",
    "            r\"E:\\projects\\image_processing\\picai_labels\\csPCa_lesion_delineations\\AI\\Bosma22a\"]\n",
    "\n",
    "sliced_train_data = []\n",
    "sliced_valid_data = []\n",
    "sliced_test_data = []\n",
    "sliced_mask_data = []\n",
    "trained_data = []\n",
    "test_data = []\n",
    "validation_data = []\n",
    "mask_data = []\n",
    "\n",
    "# iterating over all the folders including both masks and volumes\n",
    "for dataPath in dataPaths:\n",
    "    # pathToImages include path to all the files and images within the dataPath folder\n",
    "    pathToImages = list(paths.list_files(dataPath))\n",
    "    # iterarting and working on each image\n",
    "    for image in pathToImages[:20]:\n",
    "        if image[-7: ] != \"cor.mha\" and image[-7: ] != \"sag.mha\":  # since we are not working on \"cor.mha\" and \"sag.mha files\", we added this condition\n",
    "            # 1. resample the image\n",
    "            # 2. crop the image\n",
    "            # 3. flip the image and save both original and flipped image\n",
    "            # 4. normalized both flipped and original image\n",
    "            # 5. sliced both flipped and original image and added it in an array\n",
    "            # 6. write the image and append it in training, testing and validation array accordingly.\n",
    "            img = sitk.ReadImage(image)\n",
    "            resampledImage = resampling(img)\n",
    "            croppedImage = crop_or_pad(resampledImage)\n",
    "            flipImage = flipping_image(croppedImage)\n",
    "            fold =  dataPath[len(dataPath)-1]\n",
    "            if fold == \"1\" or fold == \"2\" or fold == \"4\":\n",
    "                croppedImage = normalized(croppedImage)\n",
    "                flipImage = normalized(flipImage)\n",
    "                sliced_train_data.append(slice(croppedImage))\n",
    "                sliced_train_data.append(slice(flipImage))\n",
    "                sliced_no = 0\n",
    "                for image in sliced_train_data: \n",
    "                    path = image + \"_\" + str(sliced_no)\n",
    "                    sliced_no += 1\n",
    "                    sitk.WriteImage(image,  path)\n",
    "                    trained_data.append(image)\n",
    "            if fold == \"3\":\n",
    "                croppedImage = normalized(croppedImage)\n",
    "                flipImage = normalized(flipImage)\n",
    "                sliced_valid_data.append(slice(croppedImage))\n",
    "                sliced_valid_data.append(slice(flipImage))\n",
    "                sliced_no = 0\n",
    "                for image in sliced_valid_data:\n",
    "                    path = image + \"_\" + str(sliced_no)\n",
    "                    sliced_no += 1\n",
    "                    sitk.WriteImage(image,  path)\n",
    "                    validation_data.append(image)\n",
    "            if fold == \"0\":\n",
    "                croppedImage = normalized(croppedImage)\n",
    "                flipImage = normalized(flipImage)\n",
    "                sliced_test_data.append(slice(croppedImage))\n",
    "                sliced_test_data.append(slice(flipImage))\n",
    "                sliced_no = 0\n",
    "                for image in sliced_test_data:\n",
    "                    path = image + \"_\" + str(sliced_no)\n",
    "                    sliced_no += 1\n",
    "                    sitk.WriteImage(image,  path)\n",
    "                    test_data.append(image)\n",
    "            if fold == \"b\" or fold == \"a\":\n",
    "                sliced_mask_data.append(slice(croppedImage))\n",
    "                sliced_mask_data.append(slice(flipImage))\n",
    "                sliced_no = 0\n",
    "                for image in sliced_mask_data:\n",
    "                    path = image + \"_\" + str(sliced_no)\n",
    "                    sliced_no += 1\n",
    "                    sitk.WriteImage(image,  path)\n",
    "                    mask_data.append(image)\n",
    "                \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "               \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from imutils import paths\n",
    "\n",
    "# divide data into training, testing and validation.\n",
    "train_data = []\n",
    "test_data = []\n",
    "validation_data = []\n",
    "\n",
    "train_data = [r\"picai_folder/picai/picai_public_images_fold1\",\n",
    "             r\"picai_folder/picai/picai_public_images_fold2\",\n",
    "             r\"picai_folder/picai/picai_public_images_fold4\"]\n",
    "validation_data = [r\"picai_folder/picai/picai_public_images_fold3\"]\n",
    "test_data = [r\"picai_folder/picai/picai_public_images_fold0\"]\n",
    "dataPaths_masks = [r\"picai_folder/picai/picai_labels/anatomical_delineations/whole_gland/AI/Bosma22b\",\n",
    "                   r\"picai_folder/picai/picai_labels/csPCa_lesion_delineations/AI/Bosma22a\"]\n",
    "train_ids = []\n",
    "\n",
    "# getting ids/ name of all the files in these folders.\n",
    "train_ids_1 = next(os.walk(train_data[0]))[1]\n",
    "train_ids.append(train_ids_1)\n",
    "train_ids_2 = next(os.walk(train_data[1]))[1]\n",
    "train_ids.append(train_ids_2)\n",
    "train_ids_3 = next(os.walk(train_data[2]))[1]\n",
    "train_ids.append(train_ids_3)\n",
    "\n",
    "sorted_train_ids = train_ids.sort(key = int)\n",
    "    \n",
    "test_ids = next(os.walk(test_data))[1]\n",
    "validation_ids = next(os.walk(validation_data))[1]\n",
    "\n",
    "prostate_masks_ids = next(os.walk(dataPaths_masks[0]))[1]\n",
    "lesion_mask_ids = next(os.walk(dataPaths_masks[1]))[1]\n",
    "\n",
    "# initialising three models for training.\n",
    "X_train_model1 = np.zeroes((len(train_ids), 300, 300, 1), dtype= np.uint8)\n",
    "Y_train_model1 = np.zeroes((len(train_ids), 300, 300, 1), dtype = np.bool)\n",
    "\n",
    "X_train_model2 = np.zeroes((len(train_ids), 300, 300, 1), dtype= np.uint8)\n",
    "Y_train_model2 = np.zeroes((len(train_ids), 300, 300, 1), dtype = np.bool)\n",
    "\n",
    "X_train_model3 = np.zeroes((len(train_ids), 300, 300, 1), dtype= np.uint8)\n",
    "Y_train_model3 = np.zeroes((len(train_ids), 300, 300, 1), dtype = np.bool)\n",
    "\n",
    "i_1 = 0\n",
    "i_2 = 0\n",
    "i_4 = 0\n",
    "\n",
    "# map each image with the corresponding mask.\n",
    "for n, id_ in enumerate(prostate_masks_ids):\n",
    "    mask_id = id_.split(\"_\") # to get id of the patient from the path of masks.\n",
    "\n",
    "    # to get id from path of volume images in folder1\n",
    "    path_to_images_fold1 = list(paths.list_files(train_data[0]))[i_1]\n",
    "    path_to_images_fold1_split = path_to_images_fold1.split(\"/\")\n",
    "    id_1 = path_to_images_fold1_split[-1]\n",
    "\n",
    "    # to get id from path of volume images in folder2\n",
    "    path_to_images_fold2 = list(paths.list_files(train_data[1]))[i_2]\n",
    "    path_to_images_fold2_split = path_to_images_fold2.split(\"/\")\n",
    "    id_2 = path_to_images_fold2_split[-1]\n",
    "\n",
    "    # to get id from path of volume images in folder4\n",
    "    path_to_images_fold4 = list(paths.list_files(train_data[2]))[i_4]\n",
    "    path_to_images_fold4_split = path_to_images_fold4.split(\"/\")\n",
    "    id_4 = path_to_images_fold4_split[-1]\n",
    "\n",
    "    # if image is in folder 1\n",
    "    if mask_id[0] == id_1:\n",
    "        for image in path_to_images_fold1[id_1 * 5:id_1 + 5]: # run a loop to get images for that user\n",
    "            # if image is of type \"adc.mha\" map it with prostate gland mask\n",
    "            if image[-7: ] == \"adc.mha\": \n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model1[n] = img\n",
    "                prostate_gland_image = dataPaths_masks[0] + \"\\\\\" + id_ \n",
    "                Y_train_model1[n] = sitk.ReadImage(prostate_gland_image)\n",
    "\n",
    "            # if image is of type \"hbv.mha\" map it with cancer lesion mask\n",
    "            if image[-7: ] == \"hbv.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model2[n] = img\n",
    "                cancer_lesion_image = dataPaths_masks[1] + \"\\\\\" + id_ \n",
    "                Y_train_model2[n] = sitk.ReadImage(cancer_lesion_image)\n",
    "\n",
    "            # if image is of type \"t2w.mha\" map it with cancer lesion mask  \n",
    "            if image[-7: ] == \"t2w.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model3[n] = img\n",
    "                cancer_lesion_image = dataPaths_masks[1] + id_ \n",
    "                Y_train_model3[n] = sitk.ReadImage(cancer_lesion_image)\n",
    "\n",
    "        i_1 = i_1 + 1\n",
    "\n",
    "    # if image is in folder 2\n",
    "    elif mask_id[0] == id_2:\n",
    "        for image in path_to_images_fold1[id_1:id_1 + 5]:\n",
    "            if image[-7: ] == \"adc.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model1[n] = img\n",
    "                prostate_gland_image = dataPaths_masks[0] + \"\\\\\" + id_ \n",
    "                Y_train_model1[n] = sitk.ReadImage(prostate_gland_image)\n",
    "            if image[-7: ] == \"hbv.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model2[n] = img\n",
    "                cancer_lesion_image = dataPaths_masks[1] + \"\\\\\" + id_ \n",
    "                Y_train_model2[n] = sitk.ReadImage(cancer_lesion_image)\n",
    "            if image[-7: ] == \"t2w.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model3[n] = img\n",
    "                cancer_lesion_image = dataPaths_masks[1] + \"\\\\\" + id_ \n",
    "                Y_train_model3[n] = sitk.ReadImage(cancer_lesion_image)\n",
    "\n",
    "        i_2 = i_2 + 1\n",
    "\n",
    "    # if image is in folder 4\n",
    "    elif mask_id[0] == id_4:\n",
    "        for image in path_to_images_fold1[id_1:id_1 + 5]:\n",
    "            if image[-7: ] == \"adc.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model1[n] = img\n",
    "                prostate_gland_image = dataPaths_masks[0] + \"\\\\\" + id_ \n",
    "                Y_train_model1[n] = sitk.ReadImage(prostate_gland_image)\n",
    "            if image[-7: ] == \"hbv.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model2[n] = img\n",
    "                cancer_lesion_image = dataPaths_masks[1] + \"\\\\\" + id_ \n",
    "                Y_train_model2[n] = sitk.ReadImage(cancer_lesion_image)\n",
    "            if image[-7: ] == \"t2w.mha\":\n",
    "                img = sitk.ReadImage(image)\n",
    "                X_train_model3[n] = img\n",
    "                cancer_lesion_image = dataPaths_masks[1]  + \"\\\\\" + id_ \n",
    "                Y_train_model3[n] = sitk.ReadImage(cancer_lesion_image)\n",
    "        i_4 = i_4 + 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tenserflow.keras.layers as K\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1. - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def unet(input_shape=(300, 300, 1), num_classes=1):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "    # Downsampling\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(s)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = tf.keras.layers.Dropout(0.5)(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = tf.keras.layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = tf.keras.layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = tf.keras.layers.Dropout(0.5)(conv5)\n",
    "\n",
    "    # Upsampling\n",
    "    up6 = tf.keras.layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    concat6 = tf.keras.layers.concatenate([drop4, up6])\n",
    "    conv6 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat6)\n",
    "    conv6 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    concat7 = tf.keras.layers.concatenate([conv3, up7])\n",
    "    conv7 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat7)\n",
    "    conv7 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2. 2), padding= 'same', kernel_initializer='he_normal')(conv7)\n",
    "    concat8 = tf.keras.layers.concatenate([conv2, up8])\n",
    "    conv8 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat8)\n",
    "    conv8 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2. 2), padding= 'same', kernel_initializer='he_normal')(conv8)\n",
    "    concat9 = tf.keras.layers.concatenate([conv1, up9])\n",
    "    conv9 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(concat9)\n",
    "    conv9 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "    # Output\n",
    "    outputs =  tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    # Model\n",
    "    model = tf.keras.Model([inputs], [outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = unet()\n",
    "model.compile(optimizer= 'adam', loss = dice_loss, metrics = [dice_coefficient])\n",
    "model.summary()\n",
    "checkpointers = tf.keras.callbacks.ModelCheckpoint('model_for_prostate.png', verbose = 1, save_best_only= True)\n",
    "    \n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]\n",
    "    \n",
    "results = model.fit(X_train_model1, Y_train_model1, validation_split=0.1, batch_size= 16, epochs=25, callbacks=callbacks)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c48e73646c345375b30f5f29433dbd1fb74d228e0789d012ca0fe63980fb8aef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
